{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os as os\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "# Helper libraries\n",
    "import collections\n",
    "import hashlib\n",
    "import nltk\n",
    "import json \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    #print(filename)\n",
    "    file = open(filename,'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_story_highlight_diff_files(filename, story, highlights):\n",
    "    h_filename = filename.replace(\".story\", \".highlights\")\n",
    "    print(h_filename)\n",
    "    file = open(filename,'w')\n",
    "    story = \"@story: \\n\" + story\n",
    "    file.write(story)\n",
    "    file.close()\n",
    "    h_file = open(h_filename, 'w')\n",
    "    h_file.write(\"@abstract: \\n\")\n",
    "    highlights = list(map(lambda s: \"<s>\"+s+\"<\\s>\", highlights))\n",
    "    h_file.write(' '.join(highlights))\n",
    "    h_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_story_highlight(filename, story, highlights):\n",
    "    file = open(filename,'a+')\n",
    "    file.write(\"@abstract: \\n\")\n",
    "    highlights = list(map(lambda s: \"<s>\"+s+\"<\\s>\", highlights))\n",
    "    file.write(' '.join(highlights))                 \n",
    "    story = \"\\n@story: \\n\" + story\n",
    "    file.write(story)\n",
    "    file.write(\"\\n\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a document into news story and highlights\n",
    "def split_story(doc):\n",
    "    # find first highlight\n",
    "    index = doc.find('@highlight')\n",
    "    # split into story and highlights\n",
    "    story, highlights = doc[:index], doc[index:].split('@highlight')\n",
    "    # strip extra white space around each highlight\n",
    "    highlights = [h.strip() for h in highlights if len(h) > 0]\n",
    "    return story, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load all stories in a directory\n",
    "def load_stories(directory):\n",
    "    stories = list()\n",
    "    rs_dir = \"./processed\"\n",
    "    if  os.path.exists(rs_dir):\n",
    "        shutil.rmtree(rs_dir)\n",
    "    os.makedirs(rs_dir)\n",
    "    list_of_files = listdir(directory)\n",
    "    count1 = -1\n",
    "        \n",
    "    for count,name in enumerate(list_of_files):\n",
    "        if \".story\" not in name:\n",
    "            continue\n",
    "        urlhash = os.path.splitext(name)\n",
    "        filename = directory + '/' + name\n",
    "        # load document\n",
    "        # print(filename)\n",
    "        doc = load_doc(filename)\n",
    "        # split into story and highlights\n",
    "        story, highlights = split_story(doc)\n",
    "        if(story.isspace()):\n",
    "            print(story+\" is empty!!!! \"+filename)\n",
    "            continue\n",
    "        if (count%1000 == 0):\n",
    "            count1 += 1\n",
    "            trainName = 'train'+ str(count1).zfill(3) \n",
    "        else:\n",
    "            trainName\n",
    "        fn = rs_dir + '/' + trainName\n",
    "        #write_story_highlight(fn, story, highlights)\n",
    "        # store\n",
    "        stories.append({'hash':urlhash[0], 'story':story, 'highlights':highlights})\n",
    "    return stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "    cleaned = list()\n",
    "    # prepare a translation table to remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        # strip source cnn office if it exists\n",
    "        index = line.find('(CNN) -- ')\n",
    "        if index > -1:\n",
    "            line = line[index+len('(CNN)'):]\n",
    "        index = line.find('CNN')\n",
    "        if index > -1:\n",
    "            line = line[index+len('CNN'):]\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lower case\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [w.translate(table) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "    # remove empty strings\n",
    "    cleaned = [c for c in cleaned if len(c) > 0]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we need to load up the data, the data can be found at CNN data link. We untar it in the same directory : tar xvf cnn_stories.tgz on the command line. After we load up the data, we separate out to the story and highlight portion and store it as a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/smanmoha/Desktop/project_summarization'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stories\n",
    "try:\n",
    "    file = open('cnn/stories/stories.json')\n",
    "    stories = json.load(file)\n",
    "    file.close()\n",
    "except:\n",
    "    directory = 'cnn/stories'\n",
    "    stories = load_stories(directory)\n",
    "    print('Loaded Stories %d' % len(stories))\n",
    "    # clean stories\n",
    "    for i,example in enumerate(stories):\n",
    "        example['story'] = clean_lines(example['story'].split('\\n'))\n",
    "        example['highlights'] = clean_lines(example['highlights'])\n",
    "        stories[i] = example\n",
    "    with open('cnn/stories/stories.json', 'w') as outfile:\n",
    "        json.dump(stories, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92465"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('cnn/stories/stories.json')\n",
    "stories1 = json.load(file)\n",
    "file.close()\n",
    "len(stories1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splitting to an array of story sentences and the corresponding highlight sentences we get :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_list = list(map(lambda s: s['story'], stories))\n",
    "highlights_list = list(map(lambda s: s['highlights'], stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_story_length = np.mean(list(map(lambda s: len(s), stories_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sentence_length_of_every_story = np.mean(list(map(lambda s: len(s), [s for t in stories_list for s in t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of story is 21.241 sentences and the Mean sentence length of every story is 171.595 charachters\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean length of story is {:.3f} sentences and the Mean sentence length of every story is {:.3f} charachters\".format(mean_story_length, mean_sentence_length_of_every_story))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now separating the datasets to training, dev and test datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_stories(stories, highlights, split=0.8, shuffle=False):\n",
    "    \"\"\"Generate train/test split for unsupervised tasks.\n",
    "\n",
    "    Args:\n",
    "      stories(list): list of stories\n",
    "      split (double): fraction to use as training set\n",
    "      shuffle (int or bool): seed for shuffle of input data, or False to just\n",
    "      take the training data as the first xx% contiguously.\n",
    "\n",
    "    Returns:\n",
    "      train_sentences, test_sentences ( list(list(string)) ): the train and test\n",
    "      splits\n",
    "    \"\"\"\n",
    "    sentences = np.array(list(stories), dtype=list)\n",
    "    fmt = (len(sentences), sum(map(len, sentences)))\n",
    "    print(\"Loaded {:,} stories ({:g} sentences)\".format(*fmt))\n",
    "\n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(shuffle)\n",
    "        all_sents = list(zip(sentences, highlights))\n",
    "        rng.shuffle(all_sents)\n",
    "        sentences, highlights = zip(*all_sents)\n",
    "       # rng.shuffle(sentences)  # in-place\n",
    "       # rng.shuffle(highlights)\n",
    "    split_idx = int(split * len(sentences))\n",
    "    test_dev_split_idx = int((len(sentences) - split_idx)/2)+ split_idx\n",
    "    print(split_idx, test_dev_split_idx)\n",
    "    train_stories = sentences[:split_idx]\n",
    "    dev_stories = sentences[split_idx:test_dev_split_idx]\n",
    "    test_stories = sentences[test_dev_split_idx:]\n",
    "    train_highlights = highlights[:split_idx]\n",
    "    dev_highlights = highlights[split_idx:test_dev_split_idx]\n",
    "    test_highlights = highlights[test_dev_split_idx:]\n",
    "    \n",
    "    \n",
    "    fmt = (len(train_stories), sum(map(len, train_stories)))\n",
    "    print(\"Training set: {:,} stories ({:,} sentences)\".format(*fmt))\n",
    "    fmt = (len(dev_stories), sum(map(len, dev_stories)))\n",
    "    print(\"Dev set: {:,} stories ({:,} sentences)\".format(*fmt))\n",
    "    fmt = (len(test_stories), sum(map(len, test_stories)))\n",
    "    print(\"Test set: {:,} stories ({:,} sentences)\".format(*fmt))\n",
    "\n",
    "    return train_stories, dev_stories, test_stories, train_highlights, dev_highlights, test_highlights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 92,465 stories (1.96402e+06 sentences)\n",
      "83218 87841\n",
      "Training set: 83,218 stories (1,766,718 sentences)\n",
      "Dev set: 4,623 stories (99,117 sentences)\n",
      "Test set: 4,624 stories (98,180 sentences)\n"
     ]
    }
   ],
   "source": [
    "train_stories_list, dev_stories_list, test_stories_list, train_highlights_list, dev_highlights_list, test_highlights_list \\\n",
    "= get_train_test_stories(stories_list , highlights_list, split=0.9, shuffle=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the end is closer than the beginning',\n",
       " 'ron rupert grint left harry daniel radcliffe second from right and hermione emma watson in the new film',\n",
       " 'harry potter and his friends at hogwarts are now in their sixth year of seven at the school theyve seen a lot of changes particularly as the influence of the reawakened voldemort that is he who must not be named has made itself known',\n",
       " 'and the movie series itself is now nearing its conclusion harry potter and the halfblood prince which comes out wednesday is likewise the sixth movie in the series based on jk rowlings seven harry potter books',\n",
       " 'there is one benefit to having such history director david yates says pretty much everybody going to see halfblood prince is familiar with the characters whether through the books or the movies',\n",
       " 'we made a decision we kind of crossed a line actually i think on this movie where we said you know this is the sixth one in the series its the most popular franchise probably in history do we stop and explain things to the audience who may have not seen any of the others and we said no yates said and you know why its because they can always go back to dvds they can go back to the books',\n",
       " 'indeed many fans know the books and the movies backward and forward interactive harry potter',\n",
       " 'the new film reflects the growth of the characters harry the orphaned boy wizard who has been forced to take on responsibilities beyond his youthful years ron weasley rupert grint his redhaired best friend who is finding depths of courage in himself he wasnt aware of hermione granger emma watson the bookish and indispensible member of their clan who has demonstrated key leadership qualities and all the rest preparing for the showdown with the archvillain voldemort watch the potter cast answer your questions',\n",
       " 'among the returning performers michael gambon as dumbledore alan rickman as snape maggie smith as mcgonagall robbie coltrane as hagrid and ralph fiennes as voldemort one addition is jim broadbent who plays horace slughorn a former professor brought back to hogwarts watch the stars at the rainy premiere',\n",
       " 'despite the growing darkness theres also a lightness to the new film says daniel radcliffe who plays harry unlike the previous two movies in the series which were rated this one is rated a more familyfriendly pg',\n",
       " 'i think this films funnier radcliffe said there are a couple of moments which i laughed out loud at',\n",
       " 'not that its going to be a barrel of laughs yates cautions how could it with the snakefaced voldemort growing ever stronger',\n",
       " 'it is a bit bipolar yates said on the one hand theres all this romance and on the other hand people are getting killed and bridges are being blown up',\n",
       " 'oh yes theres romance after all the main potter characters are all teenagers now with all the teenage longings',\n",
       " 'is a unit of time warner',\n",
       " 'warner bros said at the time that the film perfectly fills the gap for a major tentpole release for midsummer and added that the delay was also due to repercussions from the writers strike',\n",
       " 'but fans werent so easily placated filling message boards with angry comments and starting petitions that garnered tens of thousands of signatures warner bros president alan horn was even moved to put out a statement assuring fans that the scheduling change was not taken lightly',\n",
       " 'now that the moment is finally at hand the fans seem to have forgiven the studio according to fandangocom a movie ticketselling site harry potter and the halfblood prince is outselling transformers revenge of the fallen at the same point in the sales cycle its also in movieticketscoms top advance sellers of all time',\n",
       " 'given that transformers is by far the years topgrossing film those tidbits cant help but make the studio happy ireportcom seeing the latest potter share your review',\n",
       " 'the last of rowlings potter books harry potter and the deathly hallows is in production now as two films thats given the cast a bit of temporal whiplash when talking about halfblood prince since they completed it more than a year ago but theyve been game to talk',\n",
       " 'after all theyve come a long way since harry potter and the sorcerers stone way back in and theyre aware as anyone of the passage of time that theyre closer to the end than the beginning',\n",
       " 'its the kind of situation that leads to sentimental reflections but watson for one couldnt wait to let go of one thing her school uniform',\n",
       " 'i was like burn it she told entertainment weekly oh my god to be done with those shoes and that uniform that was an exciting day']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
